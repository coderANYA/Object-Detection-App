{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# Object Detection with MediaPipe Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PN9FvIx614"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Let's start with installing MediaPipe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxbHBsF-8Y_l",
        "outputId": "a2856e9d-bb43-44ac-b8af-19acfaae71da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\zaid\\miniconda3\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -illow (c:\\users\\zaid\\miniconda3\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q mediapipe==0.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49D7h4TVmru"
      },
      "source": [
        "Then download an off-the-shelf model. Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/object_detector#models) for more image classification models that you can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            " 65 4494k   65 2928k    0     0  6861k      0 --:--:-- --:--:-- --:--:-- 6873k\n",
            "100 4494k  100 4494k    0     0  7996k      0 --:--:-- --:--:-- --:--:-- 7998k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 5780k  100 5780k    0     0  8779k      0 --:--:-- --:--:-- --:--:-- 8797k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  1 7339k    1  128k    0     0   109k      0  0:01:07  0:00:01  0:01:06  109k\n",
            " 28 7339k   28 2112k    0     0   980k      0  0:00:07  0:00:02  0:00:05  980k\n",
            "100 7339k  100 7339k    0     0  2713k      0  0:00:02  0:00:02 --:--:-- 2713k\n"
          ]
        }
      ],
      "source": [
        "# windows\n",
        "# efficientdet_lite\n",
        "!curl -L -o models/efficientdet.tflite -q https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/int8/1/efficientdet_lite0.tflite\n",
        "# ssd\n",
        "!curl -L -o models/ssd_mobilenet_v2.tflite -q https://storage.googleapis.com/mediapipe-models/object_detector/ssd_mobilenet_v2/float16/latest/ssd_mobilenet_v2.tflite\n",
        "# EfficientDet-Lite2 mode\n",
        "!curl -L -o models/efficientdet_lite2.tflite -q https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite2/int8/latest/efficientdet_lite2.tflite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89BlskiiyGDC"
      },
      "source": [
        "## Visualization utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "id": "H4aPO-hvbw3r"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "MARGIN = 10  # pixels\n",
        "ROW_SIZE = 10  # pixels\n",
        "FONT_SIZE = 1\n",
        "FONT_THICKNESS = 1\n",
        "TEXT_COLOR = (255, 0, 0)  # red\n",
        "\n",
        "\n",
        "def visualize(\n",
        "    image,\n",
        "    detection_result\n",
        ") -> np.ndarray:\n",
        "  \"\"\"Draws bounding boxes on the input image and return it.\n",
        "  Args:\n",
        "    image: The input RGB image.\n",
        "    detection_result: The list of all \"Detection\" entities to be visualize.\n",
        "  Returns:\n",
        "    Image with bounding boxes.\n",
        "  \"\"\"\n",
        "  for detection in detection_result.detections:\n",
        "    # Draw bounding_box\n",
        "    bbox = detection.bounding_box\n",
        "    start_point = bbox.origin_x, bbox.origin_y\n",
        "    end_point = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
        "    cv2.rectangle(image, start_point, end_point, TEXT_COLOR, 3)\n",
        "\n",
        "    # Draw label and score\n",
        "    category = detection.categories[0]\n",
        "    category_name = category.category_name\n",
        "    probability = round(category.score, 2)\n",
        "    result_text = category_name + ' (' + str(probability) + ')'\n",
        "    text_location = (MARGIN + bbox.origin_x,\n",
        "                     MARGIN + ROW_SIZE + bbox.origin_y)\n",
        "    cv2.putText(image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
        "                FONT_SIZE, TEXT_COLOR, FONT_THICKNESS)\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "## Running inference and visualizing the results\n",
        "\n",
        "Here are the steps to run object detection using MediaPipe.\n",
        "\n",
        "Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/object_detector/python) to learn more about configuration options that this solution supports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "Yl_Oiye4mUuo",
        "outputId": "af44a1b9-e7f1-4585-a33b-36f06423efcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# STEP 1: Import the necessary modules.\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "\n",
        "model = 'models/efficientdet.tflite'\n",
        "# STEP 2: Create an ObjectDetector object.\n",
        "base_options = python.BaseOptions(model_asset_path=model)\n",
        "options = vision.ObjectDetectorOptions(base_options=base_options,\n",
        "                                       score_threshold=0.5)\n",
        "detector = vision.ObjectDetector.create_from_options(options)\n",
        "\n",
        "IMAGE_FILE = 'images/image.jpg'\n",
        "\n",
        "# STEP 3: Load the input image.\n",
        "image = mp.Image.create_from_file(IMAGE_FILE)\n",
        "\n",
        "# STEP 4: Detect objects in the input image.\n",
        "detection_result = detector.detect(image)\n",
        "\n",
        "# STEP 5: Process the detection result. In this case, visualize it.\n",
        "image_copy = np.copy(image.numpy_view())\n",
        "annotated_image = visualize(image_copy, detection_result)\n",
        "rgb_annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "cv2.imwrite('images/image_annotated.jpg', rgb_annotated_image)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
